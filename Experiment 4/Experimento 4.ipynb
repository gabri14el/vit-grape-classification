{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7W7v1i4gVn4"
      },
      "source": [
        "Baixando e extraindo o dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9T4CFWtdR8r"
      },
      "source": [
        "Importando as bibliotecas necessÃ¡rias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qveJTWbdV3z",
        "outputId": "7c1c0266-7e06-4be4-cbad-b2a6548de507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "TensorFlow Version 2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import glob, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print('TensorFlow Version ' + tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyTsMj2Jt086",
        "outputId": "125f091d-5a5c-4f00-d968-4a1d2d00d9e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RwM6JCdbiZQ0"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "\n",
        "diretorio = 'dataset_aumentado'\n",
        "\n",
        "TRAIN_PATH = os.path.join(diretorio, 'train')\n",
        "TEST_PATH = os.path.join(diretorio, 'test')\n",
        "VALIDATION_PATH = os.path.join(diretorio, 'validation')\n",
        "\n",
        "classes={\n",
        "    0:'CD',\n",
        "    1:'MF',\n",
        "    2:'MP',\n",
        "    3:'MR',\n",
        "    4:'MG',\n",
        "    5:'MT',\n",
        "    6:'RG',\n",
        "    7:'TA',\n",
        "    8:'TB',\n",
        "    9:'TR',\n",
        "    10:'TC',\n",
        "    11:'TN'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J1PpkIdmvyBA"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import math\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "#------------------------\n",
        "#step decay para o SGD\n",
        "def step_decay1(epoch):\n",
        "   initial_lrate = 0.01\n",
        "   flattern_factor = initial_lrate ** 2.25\n",
        "   epochs_drop = 5.0\n",
        "   #drop modelado como modelado no artigo\n",
        "   drop = initial_lrate **(flattern_factor/epochs_drop)\n",
        "   \n",
        "   lrate = initial_lrate * math.pow(drop,  \n",
        "           math.floor((epoch)/epochs_drop))\n",
        "   return lrate\n",
        "\n",
        "#step decay\n",
        "def step_decay2(epoch):\n",
        "   initial_lrate = 0.0001\n",
        "   flattern_factor = initial_lrate ** 2.25\n",
        "   epochs_drop = 5.0\n",
        "   #drop modelado como modelado no artigo\n",
        "   drop = initial_lrate **(flattern_factor/epochs_drop)\n",
        "   \n",
        "   lrate = initial_lrate * math.pow(drop,  \n",
        "           math.floor((epoch)/epochs_drop))\n",
        "   return lrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keKbeo__kZDa",
        "outputId": "74791d57-023d-4bf1-ddb5-060229e302d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6718 images belonging to 12 classes.\n",
            "Found 132 images belonging to 12 classes.\n",
            "Found 72 images belonging to 12 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=vit.preprocess_inputs)\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=vit.preprocess_inputs)\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=vit.preprocess_inputs)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(TRAIN_PATH,\n",
        "                                              target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                              class_mode='categorical',\n",
        "                                              batch_size=BATCH_SIZE)\n",
        "\n",
        "val_set = train_datagen.flow_from_directory(VALIDATION_PATH,\n",
        "                                              target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                              class_mode='categorical',\n",
        "                                              batch_size=BATCH_SIZE)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(TEST_PATH, \n",
        "                                            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                            class_mode='categorical',\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cxyZvmvjlIts"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet vit-keras\n",
        "\n",
        "from vit_keras import vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrmd28sIllkq",
        "outputId": "aac2c5eb-4998-45a7-ff0b-b762147f4b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_32_imagenet21k+imagenet2012.npz\n",
            "353255424/353253686 [==============================] - 14s 0us/step\n",
            "353263616/353253686 [==============================] - 14s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vit_model = vit.vit_b32(\n",
        "        image_size = IMAGE_SIZE,\n",
        "        activation = 'softmax',\n",
        "        pretrained = True,\n",
        "        include_top = False,\n",
        "        pretrained_top = False,\n",
        "        classes = len(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-_MyJ9lmCk6A"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
        "\n",
        "x = tf.keras.layers.Flatten()(vit_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "output = Dense(len(classes), activation='softmax')(x)\n",
        "model = tf.keras.models.Model(vit_model.input, output) \n",
        "\n",
        "\n",
        "for layer in range(len(vit_model.layers)):\n",
        "    vit_model.layers[layer].treinable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqJvsgW5Cv0Y",
        "outputId": "90a65a3f-1e99-4105-8105-c51be386f280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.8851 - accuracy: 0.4916 - f1_m: 0.2803 - precision_m: 0.6273 - recall_m: 0.1952\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.64062, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 189s 389ms/step - loss: 1.8851 - accuracy: 0.4916 - f1_m: 0.2803 - precision_m: 0.6273 - recall_m: 0.1952 - val_loss: 1.6031 - val_accuracy: 0.6406 - val_f1_m: 0.5538 - val_precision_m: 0.8108 - val_recall_m: 0.4297 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.3839 - accuracy: 0.7926 - f1_m: 0.6928 - precision_m: 0.9266 - recall_m: 0.5634\n",
            "Epoch 00002: val_accuracy improved from 0.64062 to 0.75781, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 161s 385ms/step - loss: 1.3839 - accuracy: 0.7926 - f1_m: 0.6928 - precision_m: 0.9266 - recall_m: 0.5634 - val_loss: 1.4012 - val_accuracy: 0.7578 - val_f1_m: 0.7171 - val_precision_m: 0.9206 - val_recall_m: 0.5938 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.2067 - accuracy: 0.9021 - f1_m: 0.8325 - precision_m: 0.9686 - recall_m: 0.7365\n",
            "Epoch 00003: val_accuracy improved from 0.75781 to 0.78125, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 161s 384ms/step - loss: 1.2067 - accuracy: 0.9021 - f1_m: 0.8325 - precision_m: 0.9686 - recall_m: 0.7365 - val_loss: 1.3439 - val_accuracy: 0.7812 - val_f1_m: 0.7706 - val_precision_m: 0.9303 - val_recall_m: 0.6641 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.1293 - accuracy: 0.9466 - f1_m: 0.8904 - precision_m: 0.9859 - recall_m: 0.8175\n",
            "Epoch 00004: val_accuracy improved from 0.78125 to 0.82812, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 162s 385ms/step - loss: 1.1293 - accuracy: 0.9466 - f1_m: 0.8904 - precision_m: 0.9859 - recall_m: 0.8175 - val_loss: 1.2624 - val_accuracy: 0.8281 - val_f1_m: 0.7994 - val_precision_m: 0.9560 - val_recall_m: 0.6953 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0841 - accuracy: 0.9718 - f1_m: 0.9257 - precision_m: 0.9926 - recall_m: 0.8711\n",
            "Epoch 00005: val_accuracy improved from 0.82812 to 0.85156, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 161s 385ms/step - loss: 1.0841 - accuracy: 0.9718 - f1_m: 0.9257 - precision_m: 0.9926 - recall_m: 0.8711 - val_loss: 1.2649 - val_accuracy: 0.8516 - val_f1_m: 0.7896 - val_precision_m: 0.9253 - val_recall_m: 0.6953 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0589 - accuracy: 0.9812 - f1_m: 0.9407 - precision_m: 0.9961 - recall_m: 0.8941\n",
            "Epoch 00006: val_accuracy did not improve from 0.85156\n",
            "419/419 [==============================] - 157s 375ms/step - loss: 1.0589 - accuracy: 0.9812 - f1_m: 0.9407 - precision_m: 0.9961 - recall_m: 0.8941 - val_loss: 1.2677 - val_accuracy: 0.8359 - val_f1_m: 0.7855 - val_precision_m: 0.9342 - val_recall_m: 0.6875 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0371 - accuracy: 0.9887 - f1_m: 0.9567 - precision_m: 0.9982 - recall_m: 0.9208\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.85156\n",
            "419/419 [==============================] - 157s 374ms/step - loss: 1.0371 - accuracy: 0.9887 - f1_m: 0.9567 - precision_m: 0.9982 - recall_m: 0.9208 - val_loss: 1.2610 - val_accuracy: 0.8203 - val_f1_m: 0.8086 - val_precision_m: 0.9403 - val_recall_m: 0.7109 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0191 - accuracy: 0.9934 - f1_m: 0.9661 - precision_m: 0.9990 - recall_m: 0.9373Restoring model weights from the end of the best epoch: 5.\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.85156\n",
            "419/419 [==============================] - 158s 376ms/step - loss: 1.0191 - accuracy: 0.9934 - f1_m: 0.9661 - precision_m: 0.9990 - recall_m: 0.9373 - val_loss: 1.2608 - val_accuracy: 0.8281 - val_f1_m: 0.7899 - val_precision_m: 0.9499 - val_recall_m: 0.6797 - lr: 0.0020\n",
            "Epoch 00008: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d9c60e190>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer = tfa.optimizers.RectifiedAdam(learning_rate = learning_rate)\n",
        "\n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2), \n",
        "              metrics=['accuracy', f1_m,precision_m, recall_m])\n",
        "\n",
        "model.compile(optimizer='sgd', loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
        "           metrics=['accuracy', f1_m,precision_m, recall_m])\n",
        "\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN = train_set.n // train_set.batch_size\n",
        "STEP_SIZE_VALID = val_set.n // val_set.batch_size\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',\n",
        "                                                 factor = 0.2,\n",
        "                                                 patience = 2,\n",
        "                                                 verbose = 1,\n",
        "                                                 min_delta = 1e-4,\n",
        "                                                 min_lr = 1e-6,\n",
        "                                                 mode = 'max')\n",
        "\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
        "                                                 min_delta = 1e-4,\n",
        "                                                 patience = 3,\n",
        "                                                 mode = 'max',\n",
        "                                                 restore_best_weights = True,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath = '/content/gdrive/MyDrive/model_best7_v0.h5',\n",
        "                                                  monitor = 'val_accuracy', \n",
        "                                                  verbose = 1, \n",
        "                                                  save_best_only = True,\n",
        "                                                  save_weights_only = True,\n",
        "                                                  mode = 'max')\n",
        "\n",
        "callbacks = [earlystopping, reduce_lr, checkpointer]\n",
        "\n",
        "\n",
        "\n",
        "model.fit(x = train_set,\n",
        "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "          validation_data = val_set,\n",
        "          validation_steps = STEP_SIZE_VALID,\n",
        "          epochs = EPOCHS,\n",
        "          callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tgVxCdv-gOX",
        "outputId": "d0735ecf-311b-4045-9829-baf0887b5618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0626 - accuracy: 0.9758\n",
            "Epoch 00001: val_accuracy did not improve from 0.85156\n",
            "419/419 [==============================] - 231s 482ms/step - loss: 1.0626 - accuracy: 0.9758 - val_loss: 1.3217 - val_accuracy: 0.7734 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0217 - accuracy: 0.9887\n",
            "Epoch 00002: val_accuracy improved from 0.85156 to 0.85938, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 200s 477ms/step - loss: 1.0217 - accuracy: 0.9887 - val_loss: 1.1890 - val_accuracy: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0154 - accuracy: 0.9794\n",
            "Epoch 00003: val_accuracy did not improve from 0.85938\n",
            "419/419 [==============================] - 198s 473ms/step - loss: 1.0154 - accuracy: 0.9794 - val_loss: 1.3450 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.9809\n",
            "Epoch 00004: val_accuracy improved from 0.85938 to 0.86719, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 202s 482ms/step - loss: 1.0070 - accuracy: 0.9809 - val_loss: 1.2234 - val_accuracy: 0.8672 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 0.9666 - accuracy: 0.9924\n",
            "Epoch 00005: val_accuracy did not improve from 0.86719\n",
            "419/419 [==============================] - 198s 473ms/step - loss: 0.9666 - accuracy: 0.9924 - val_loss: 1.2951 - val_accuracy: 0.8281 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 0.9581 - accuracy: 0.9958\n",
            "Epoch 00006: val_accuracy improved from 0.86719 to 0.88281, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 202s 482ms/step - loss: 0.9581 - accuracy: 0.9958 - val_loss: 1.1848 - val_accuracy: 0.8828 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 0.9412 - accuracy: 1.0000\n",
            "Epoch 00007: val_accuracy improved from 0.88281 to 0.90625, saving model to /content/gdrive/MyDrive/model_best7_v0.h5\n",
            "419/419 [==============================] - 202s 483ms/step - loss: 0.9412 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 0.9387 - accuracy: 1.0000\n",
            "Epoch 00008: val_accuracy did not improve from 0.90625\n",
            "419/419 [==============================] - 198s 473ms/step - loss: 0.9387 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.8984 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 0.9590 - accuracy: 0.9896\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.90625\n",
            "419/419 [==============================] - 198s 472ms/step - loss: 0.9590 - accuracy: 0.9896 - val_loss: 1.6385 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "419/419 [==============================] - ETA: 0s - loss: 0.9673 - accuracy: 0.9888Restoring model weights from the end of the best epoch: 7.\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.90625\n",
            "419/419 [==============================] - 198s 473ms/step - loss: 0.9673 - accuracy: 0.9888 - val_loss: 1.2138 - val_accuracy: 0.8750 - lr: 2.0000e-05\n",
            "Epoch 00010: early stopping\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#model.save('model.h5', save_weights_only = True)\n",
        "\n",
        "model.load_weights('/content/gdrive/MyDrive/model_best7_v0.h5')\n",
        "\n",
        "learning_rate = 1e-6\n",
        "\n",
        "\n",
        "#descongela as camadas\n",
        "for layer in range(len(vit_model.layers)):\n",
        "    vit_model.layers[layer].treinable=True\n",
        "\n",
        "  \n",
        "\n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2), \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x = train_set,\n",
        "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "          validation_data = val_set,\n",
        "          validation_steps = STEP_SIZE_VALID,\n",
        "          epochs = EPOCHS,\n",
        "          callbacks = callbacks)\n",
        "\n",
        "model.load_weights('/content/gdrive/MyDrive/model_best7_v0.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "P03ty_iOuIXc",
        "outputId": "ff0782a4-06a9-4531-e389-18a9be0b6593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Codega', 'Malvasia Fina', 'Malvasia Preta', 'Malvasia Rei', 'Moscatel Galego', 'Mourisco Tinto', 'Rabigato', 'Tinta Amarela', 'Tinta Barroca', 'Tinta Roriz', 'Tinto Cao', 'Touriga Nacional']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CD       1.00      0.50      0.67         6\n",
            "          MF       0.86      1.00      0.92         6\n",
            "          MP       1.00      1.00      1.00         6\n",
            "          MR       0.60      1.00      0.75         6\n",
            "          MG       1.00      1.00      1.00         6\n",
            "          MT       1.00      0.83      0.91         6\n",
            "          RG       1.00      0.83      0.91         6\n",
            "          TA       1.00      1.00      1.00         6\n",
            "          TB       1.00      1.00      1.00         6\n",
            "          TR       1.00      1.00      1.00         6\n",
            "          TC       0.86      1.00      0.92         6\n",
            "          TN       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.92        72\n",
            "   macro avg       0.94      0.92      0.92        72\n",
            "weighted avg       0.94      0.92      0.92        72\n",
            "\n",
            "Confusion matrix, without normalization\n",
            "[[3 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 6 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 6 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 6 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 6 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 5 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 5 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 6 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 6 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 6 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 6 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 5]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes={\n",
        "    'Codega':'CD',\n",
        "    'Malvasia Fina':'MF',\n",
        "    'Malvasia Preta':'MP',\n",
        "    'Malvasia Rei':'MR',\n",
        "    'Moscatel Galego':'MG',\n",
        "    'Mourisco Tinto':'MT',\n",
        "    'Rabigato':'RG',\n",
        "    'Tinta Amarela':'TA',\n",
        "    'Tinta Barroca':'TB',\n",
        "    'Tinta Roriz':'TR',\n",
        "    'Tinto Cao':'TC',\n",
        "    'Touriga Nacional':'TN'\n",
        "}\n",
        "\n",
        "from sklearn import metrics\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def confusion_matrix(test_data_generator, model):\n",
        "  test_data_generator.reset()\n",
        "  predictions = model.predict(test_data_generator, steps=test_set.samples)\n",
        "  # Get most likely class\n",
        "  predicted_classes = np.argmax(predictions, axis=1)\n",
        "  true_classes = test_data_generator.classes\n",
        "  class_labels = list(test_data_generator.class_indices.keys())\n",
        "  print(class_labels)\n",
        "  class_labels = [classes[x] for x in class_labels]  \n",
        "\n",
        "  report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "  cm = metrics.confusion_matrix(true_classes, predicted_classes)\n",
        "  print(report)\n",
        "  plot_confusion_matrix(cm, class_labels)\n",
        "\n",
        "\n",
        "confusion_matrix(test_set, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YilmpsdwXhWI"
      },
      "outputs": [],
      "source": [
        "dot_img_file = 'model_1.png'\n",
        "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
        "\n",
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[ViT]_DS12_Experimento_3_v0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
